\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,       % false: boxed links; true: colored links
linkcolor=red,          % color of internal links (change box color with linkbordercolor)
citecolor=blue,      % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan          % color of external links
}

\usepackage{array}

\externaldocument{../../SRS/SRS}

\input{../../Comments}
\input{../../Common}

\begin{document}

\title{Module Interface Specification for \progname{}}

\author{\authname}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
January 17, 2024 & 1.0 & Revision 0\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

See SRS Documentation at \url{https://github.com/MichaelBreau/nlp-mentalhealth/blob/main/docs/SRS/index.pdf}

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}

The following document details the Module Interface Specifications for
Natural Language Processing for Mental Health Risk Prediction 

Complementary documents include the System Requirement Specifications
and Module Guide.  The full documentation and implementation can be
found at \url{https://github.com/MichaelBreau/nlp-mentalhealth}.

\section{Notation}

The structure of the MIS for modules comes from \citet{HoffmanAndStrooper1995},
with the addition that template modules have been adapted from
\cite{GhezziEtAl2003}.  The mathematical notation comes from Chapter 3 of
\citet{HoffmanAndStrooper1995}.  For instance, the symbol := is used for a
multiple assignment statement and conditional rules follow the form $(c_1
\Rightarrow r_1 | c_2 \Rightarrow r_2 | ... | c_n \Rightarrow r_n )$.

The following table summarizes the primitive data types used by \progname. 

\begin{center}
\renewcommand{\arraystretch}{1.2}
\noindent 
\begin{tabular}{l l p{7.5cm}} 
\toprule 
\textbf{Data Type} & \textbf{Notation} & \textbf{Description}\\ 
\midrule
character & char & a single symbol or digit\\
list & $$[item, item,...]$$ & a list of objects of the same type\\
dict & $<key: T, val: T>$ & a dictionary of key value pairs\\
integer & $\mathbb{Z}$ & a number without a fractional component in (-$\infty$, $\infty$) \\
natural number & $\mathbb{N}$ & a number without a fractional component in [1, $\infty$) \\
real & $\mathbb{R}$ & any number in (-$\infty$, $\infty$)\\
\bottomrule
\end{tabular} 
\end{center}

\noindent
The specification of \progname \ uses some derived data types: sequences, strings, and
tuples. Sequences are lists filled with elements of the same data type. Strings
are sequences of characters. Tuples contain a list of values, potentially of
different types. In addition, \progname \ uses functions, which
are defined by the data types of their inputs and outputs. Local functions are
described by giving their type signature followed by their specification.

\section{Module Decomposition}

The following table is taken directly from the Module Guide document for this project.

\begin{table}[h!]
\centering
\begin{tabular}{p{0.2\textwidth} p{0.3\textwidth} p{0.4\textwidth}}
\toprule
\textbf{Level 1} & \textbf{Level 2} & \textbf{Level 3}\\
\midrule

{Hardware-Hiding} & None \\
\midrule

\multirow{3}{*}{Behaviour-Hiding} & \\ \cline{2-3}
& \multirow{2}{*}{Eating Disorder IO} & ED Input\\
& & ED Output\\
\midrule

\multirow{4}{*}{Software Decision} 
& \multirow{5}{*}{Depression Pipeline} & Depression Main\\ 
& & Depression Data Processing\\
& & Depression Feature Extraction\\
& & Depression Output\\ 
& & Depression Evaluation\\\cline{2-3}
& \multirow{4}{*}{Anorexia Pipeline} & Anorexia Main\\ 
& & Anorexia Parser\\
& & Anorexia Training\\
& & Anorexia Predictor\\ \cline{2-3}
& \multirow{5}{*}{Eating Disorder Pipeline} & ED Pipeline Manager\\
& & ED Tokenizer\\
& & ED Representation Model\\
& & ED Prediction Model\\
& & ED Transformation 1...n (represents multiple modules)\\
\bottomrule

\end{tabular}
\caption{Module Hierarchy}
\label{TblMH}
\end{table}

\newpage
~\newpage

\section{MIS for Search for Symptoms of Depression Module} \label{Module} 

\subsection{depression\_main}

Task 1 - Search for Symptoms of Depression for User Sentences - Main Module


\subsection{Uses}

Used for combining the various module functionalities in a pipeline format.\\ 
Uses depression\_process\_data, depression\_feature\_extraction, depression\_output, \\ 
depression\_accuracy\_evaluation

\subsection{Syntax}

\subsubsection{Exported Constants}

None 


\subsubsection{Exported Access Programs}

\begin{center}

\begin{tabular}{p{3cm}p{2cm}p{2cm}p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
N/A & N/A & N/A & - \\
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None


\subsubsection{Access Routine Semantics}

None


\subsubsection{Local Functions}

None

\subsection{depression\_process\_data}

Task 1 - Search for Symptoms of Depression for User Sentences - Data Processing Module

\subsection{Uses}

Used for parsing user posts and golden truth files

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
pathaddress & String & String & - \\
parsedata & String & Dictionary & - \\
processdata & String & Dictionary  & - \\
goldentruthsentences & String & Dictionary & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

\begin{itemize}
\item Data from user posts are in multiple trec file and the ground truth file is in a csv file and are present in the current task directory.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent pathaddress():
\begin{itemize}
\item transition: None
\item output: The path address for the data files
\item exception: None
\end{itemize}

\noindent parsedata():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to a list of strings containing user posts
\item exception: None
\end{itemize}

\noindent parsedata():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to a list of strings containing user posts, with gibberish information removed
\item exception: None
\end{itemize}

\noindent goldentruthsentences():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to an integer representing their depression symptom 
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\subsection{depression\_feature\_extraction}

Task 1 - Search for Symptoms of Depression for User Sentences - Feature Extraction Module

\subsection{Uses}

Used for predicting the top depression sentences that matches each symptom of depression

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
getFeatureWords & List & Dictionary & - \\
feature\_2\_vec & Dictionary, Dictionary & Dictionary & - \\
getEmbeddings & Dictionary, Dictionary,  & Dictionary & - \\
 & Dictionary &  &  \\
tf\_idf & Dictionary, Dictionary & Dictionary & - \\
 & Integer &  &  \\
vectorizePosts & Dictionary, Dictionary & Dictionary & - \\
 & Dictionary &  &  \\
cosine\_sim & Dictionary, List & Dictionary & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None

\subsubsection{Access Routine Semantics}

\noindent getFeatureWords():
\begin{itemize}
\item transition: None
\item output: A dictionary where each key represents a depression symptom, and the corresponding value is a list of strings representing feature words extracted from files.
\item exception: None
\end{itemize}

\noindent feature\_2\_vec():
\begin{itemize}
\item transition: None
\item output: Produces a dictionary where each key corresponds to a question number, and the associated value is a numpy array representing the vectorized features for that question. 
\item exception: None
\end{itemize}

\noindent getEmbeddings():
\begin{itemize}
\item transition: None
\item output: Outputs a dictionary containing word embeddings, filtered based on words present in the data, feature sets, and a given set of word embeddings
\item exception: None
\end{itemize}

\noindent tf\_idf():
\begin{itemize}
\item transition: None
\item output: Generates a dictionary where each key represents a document ID, and the associated value is a list of strings representing the top-k words based on TF-IDF scores.
\item exception: None
\end{itemize}

\noindent vectorizePosts():
\begin{itemize}
\item transition: None
\item output: A dictionary where each key represents a sentence, and the corresponding value is a numpy array representing the vectorized representation of the sentence.
\item exception: None
\end{itemize}

\noindent cosine\_sim():
\begin{itemize}
\item transition: None
\item output: A dictionary where each key represents a sentence, and the associated value is a float representing the cosine similarity between the sentence vector and a target vector.
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\subsection{depression\_output}

Task 1 - Search for Symptoms of Depression for User Sentences - Ouput Module

\subsection{Uses}

Used for generating output into a specific format

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
write\_to\_text\_file & Any, String & - & - \\
write\_dict\_to\_file & Dictionary, String & - & - \\
get\_questions & String & List & - \\
get\_top\_matchs & String, Dictionary & Dictionary & - \\

\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None

\subsubsection{Access Routine Semantics}

\noindent write\_to\_text\_file():
\begin{itemize}
\item transition: None
\item output: None
\item exception: None
\end{itemize}
\noindent write\_dict\_to\_file():
\begin{itemize}
\item transition: None
\item output: None
\item exception: None
\end{itemize}
\noindent get\_questions():
\begin{itemize}
\item transition: None
\item output: A list of strings representing symptom names extracted from a JSON questionnaire file.
\item exception: None
\end{itemize}
\noindent get\_top\_matchs():
\begin{itemize}
\item transition: None
\item output: A dictionary where each key represents a question index, and the associated value is a list of top matches based on user responses.
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\subsection{depression\_accuracy\_evaluation}

Task 1 - Search for Symptoms of Depression for User Sentences - Accuracy Evaluation Module


\subsection{Uses}

Used for determining the accuracy of generated results using various metrics

\subsection{Syntax}

\subsubsection{Exported Constants}

None 


\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{5.5cm} p{3cm} p{2.5cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
golden\_truth\_sentence\_data & String & Dictionary & - \\
get\_average\_precisions & Dictionary,  & List & - \\
 & Dictionary  &  &  \\
print\_accuracy & List, List, String & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None


\subsubsection{Access Routine Semantics}

\noindent golden\_truth\_sentence\_data():
\begin{itemize}
\item transition: None
\item output: A dictionary where each key represents a question index, and the associated value is a list of sentence IDs and their relevances based on a provided CSV file.
\item exception: None
\end{itemize}
\noindent get\_average\_precisions():
\begin{itemize}
\item transition: None
\item output: A list containing precision values and NDCG values calculated based on the provided sentence scores and golden truth values.
\item exception: None
\end{itemize}
\noindent print\_accuracy():
\begin{itemize}
\item transition: None
\item output: None
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\newpage

\section{MIS for Early Detection of Signs of Anorexia Module} \label{Module} 

\subsection{anorexia\_main}

Task 2 - Early Detection of Signs of Anorexia using User Posts - Main Module

\subsection{Uses}

Used for combining the various module functionalities in a pipeline format

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
N/A & N/A & N/A & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None

\subsubsection{Access Routine Semantics}

None

\subsubsection{Local Functions}

None

\subsection{anorexia\_parser}

Task 2 - Early Detection of Signs of Anorexia using User Posts - Parser Module

\subsection{Uses}

Used for parsing user posts and golden truth files

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
pathaddress & String & String & - \\
parsedata & String & Dictionary & - \\
goldentruth & String & Dictionary & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

\begin{itemize}
\item Data from user posts are in an xml file and the ground truth file is in a txt file and are present in the current working directory.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent pathaddress():
\begin{itemize}
\item transition: None
\item output: The path address for the data files
\item exception: None
\end{itemize}

\noindent parsedata():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to a list of strings containing user posts
\item exception: None
\end{itemize}

\noindent goldentruth():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to an integer representing their anorexia status (0 or 1)
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\subsection{anorexia\_training}

Task 2 - Early Detection of Signs of Anorexia using User Posts - Training Module

\subsection{Uses}

Used for training bertopic model on parsed data using golden truth values

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
bert & Dictionary & List, List & - \\
predictor & List, List & Dictionary & - \\
calculateaccuracy & Dictionary, Dictionary & None & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

\begin{itemize}
\item The model is trained on accurate data with correctly linked user-truth values.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent bert():
\begin{itemize}
\item transition: None
\item output: List 1: List of usernames, List 2: List of topics generated from the bertopic model with the indexes corresponding to the usernames from the first list
\item exception: None
\end{itemize}

\noindent predictor():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys and the predicted 0 or 1 integer linked
\item exception: None
\end{itemize}

\noindent calculateaccuracy():
\begin{itemize}
\item transition: None
\item output: Accuracy scores comparing golden truth to predictor values
\[ Precision (P) = \frac{|u \in U: d = g = 1|}{|u \in U: d = 1|} \]
\[ Recall (R) = \frac{|u \in U: d = g = 1|}{|u \in U: g = 1|} \]
\[ F-Score (F) = \frac{2*P*R}{P+R} \]
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\subsection{anorexia\_predictor}

Task 2 - Early Detection of Signs of Anorexia using User Posts - Predictor Module

\subsection{Uses}

Used for predicting new documents unseen by training

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
predict\_new & String & Integer & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None

\subsubsection{Access Routine Semantics}

\noindent predict\_new():
\begin{itemize}
\item transition: None
\item output: Integer 0 or 1 corresponding to the model prediction of anorexia negative or positive 
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\newpage

\section{MIS for Measuring the Severity of the Signs of Eating Disorders} \label{Module}

\subsection{Module ED Parser}

\subsection{Uses}

None

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{3cm} p{3cm} p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
parse\_json & $String$ & $Dict$ & $IncorrectFileFormat$ \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

The input to parse\_json will be a path to a file on the disk.

\subsubsection{Access Routine Semantics}

\noindent parse\_json($pathaddress: String$):
\begin{itemize}
\item transition: None
\item input: a path to a file on the disk
\item output: $Dict\ of <username: <labels: [\text{questionnaire scores}],  posts: [\text{user's post history}]>>$
\item exception: If the input file is not correctly formatted

format of input file should have one user on each line and each user should be stored as:

\{``id": ``subjectID", ``label": [``0-6", ``0-6", ..., ``0-6" (22 entries)], ``posts": [\{``date": ``YYYY-MM-DD HH:MM:SS", ``title": ``title text", ``body": ``body text"\}, more posts]\}
\end{itemize}

\subsubsection{Local Functions}

None

\subsection{Module ED Cleaner}

\subsection{Uses}

Parser

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{3cm} p{3cm} p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
clean\_data & $Dict$ & $Dict$ & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

The parser is working correctly

\subsubsection{Access Routine Semantics}

\noindent clean\_data($pathaddress: String$):
\begin{itemize}
\item transition: None
\item input: $Dict\ of <username: <labels: [\text{questionnaire scores}],  posts: [\text{user's post history}]>>$
\item output: $Dict\ of <username: <labels: [\text{questionnaire scores}],  posts: [\text{user's post history}]>>$ where the user's posts no longer have a title and body but a single text field instead
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Module ED Output}

\subsection{Uses}

ED Data Storage

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{6cm} p{2cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
output & $DataStorage$ & None & $NoPredictions$ \\
\hline

\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

The rest of the pipeline up to this point will function correctly

\subsubsection{Access Routine Semantics}

\noindent output(ds : $DataStorage$):
\begin{itemize}
\item transition: writes predictions in $ds$ to a file where each line represents predictions for a user and is of the format "username: 0-6, 0-6, ..., 0-6" with twenty to answers of 0 to 6.
\item output: None
\item exception: $NoPredictions$: raised if $ds$ does not have predictions stored
\end{itemize}

\subsubsection{Local Functions}

None



\subsection{Template Module ED Data Storage}

\subsection{Uses}

ED Cleaner

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{5cm} p{3cm} p{2cm} p{6cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
initialize & $Dict$, $Int$ & $DataStorage$ & None \\
get\_num\_posts & None & $Int$ & None \\
get\_num\_users & None & $Int$ & None \\
get\_embeddings & None & $List$ & $NoEmbeddings$ \\
set\_embeddings & $List$ & None & $WrongSize$ \\
get\_texts & None & $List$ & $NoText$ \\
set\_texts & $List$ & None & $WrongSize$ \\
get\_post\_user\_labels & None & $2d List$ & $NoLabels$ \\
get\_post\_labels & None & $2d List$ & $NoLabels$ \\
set\_post\_labels & $Int$, $List$ & None & $WrongSize$ \\
get\_user\_labels & None & $Dict$ & $NoLabels$ \\
get\_user\_predictions & None & $Dict$ & $NoLabels$ \\
set\_user\_predictions & $String$, $List$ & None & $UserDoesNotExist$ \\
get\_user\_embeddings & $String$ & $List$ & $NoEmbeddings$, $UserDoesNotExist$ \\
get\_user\_texts & $String$ & $List$ & $NoText$, $UserDoesNotExist$ \\
get\_user\_post\_labels & $String$ & $2d List$ & $NoLabels$, $UserDoesNotExist$ \\
get\_user\_post\_label\_counts & $String$, $Int$ & $Tuple$ & $NoLabels$, $UserDoesNotExist$ \\
get\_state & None & $Dict$ & None \\
set\_state & $Int$, $Bool$ & None & $NotASplit$ \\

\hline

\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

Split : $Int$ stores the current train/test split the DataStorage is focused on, must be between -1 and the number of splits specified at initialization minus 1. -1 means the DataStorage is focused on the entirety of the data.

\noindent Train : $Bool$ stores whether the DataStorage is currently focused on the train split or the test split

\noindent TheData : Potentially multiple different data structure and lists storing the data, includes space to store a post history for each user, expected scores for each user, predicted scores for each user, embeddings for each post, and scores for each post. All of these fields can be changed and viewed through getters and setters

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

ED Cleaning is working correctly

\subsubsection{Access Routine Semantics}

\noindent initialize(data : $Dict$, num\_splits : $Int$)
\begin{itemize}
\item input: data is a dictionary of the form produced by ED Cleaning
\item transition: constructs a DataStorage() object, stores the post history and expected scores of each user in TheData, produces num\_splits train/test splits on the data, and sets the current split to -1
\item output: the DataStorage() object constructed
\item exception: None
\end{itemize}

\noindent get\_num\_posts()
\begin{itemize}
\item input: None
\item transition: None
\item output: the number of posts stored in the DataStorage
\item exception: None
\end{itemize}

\noindent get\_num\_users()
\begin{itemize}
\item input: None
\item transition: None
\item output: the number of users stored in the DataStorage
\item exception: None
\end{itemize}

\noindent get\_embeddings()
\begin{itemize}
\item input: None
\item transition: None
\item output: a list of embeddings for the currently focused split
\item exception: $NoEmbeddings$ thrown if the DataStorage does not currently have embeddings stored
\end{itemize}

\noindent set\_embeddings(embeddings : $List$)
\begin{itemize}
\item input: a list of embeddings
\item transition: sets the embeddings for the current split to the input
\item output: None
\item exception: $WrongSize$ thrown if embeddings are not the same length as the currently focused split
\end{itemize}

\noindent get\_texts()
\begin{itemize}
\item input: None
\item transition: None
\item output: a list of texts for the currently focused split
\item exception: $NoTexts$ thrown if the DataStorage does not currently have texts stored
\end{itemize}

\noindent set\_texts(texts : $List$)
\begin{itemize}
\item input: a list of texts
\item transition: sets the texts for the current split to the input
\item output: None
\item exception: $WrongSize$ thrown if texts are not the same length as the currently focused split
\end{itemize}

\noindent get\_post\_user\_labels()
\begin{itemize}
\item input: None
\item transition: None
\item output: a list of user labels for each post, the label for each post is the score of the author of said post. Gets these labels for the currently focused split
\item exception: $NoLabels$ thrown if the DataStorage does not currently have user labels stored
\end{itemize}

\noindent get\_post\_labels()
\begin{itemize}
\item input: None
\item transition: None
\item output: a list of labels for each post for the currently focused split
\item exception: $NoLabels$ thrown if the DataStorage does not currently have post labels stored
\end{itemize}

\noindent set\_post\_labels(question : $int$, labels : $List$)
\begin{itemize}
\item input: question is the questionnaire question the labels are for, labels is the labels to set
\item transition: sets the post labels for question to labels for the current split
\item output: None
\item exception: $WrongSize$ thrown if labels are not the same length as the currently focused split
\end{itemize}

\noindent get\_user\_labels()
\begin{itemize}
\item input: None
\item transition: None
\item output: a dictionary of the form $<``\text{username}" : [\text{actual scores for each question}]>$ that maps a user's username to the scores they filled on the EDE-Q
\item exception: $NoLabels$ thrown if the DataStorage does not currently have user labels stored
\end{itemize}

\noindent get\_user\_predictions()
\begin{itemize}
\item input: None
\item transition: None
\item output: a dictionary of the form $<``\text{username}" : [\text{predicted scores for each question}]>$ that maps a user's username to the scores the model predicts they have on the EDE-Q
\item exception: $NoLabels$ thrown if the DataStorage does not currently have predicted user labels stored
\end{itemize}

\noindent set\_user\_predictions(user : $String$, preds : $List$)
\begin{itemize}
\item input: user is the user to set predictions for, preds are the predictions to set
\item transition: sets the predicted user labels for user to preds
\item output: None
\item exception: $UserDoesNotExist$ thrown if user does not exist in the DataStorage
\end{itemize}

\noindent get\_user\_embeddings(user : $String$)
\begin{itemize}
\item input: the user to get embeddings for
\item transition: None
\item output: list of embeddings for user
\item exception: $NoEmbeddings$ thrown if the DataStorage does not currently have embeddings stored, $UserDoesNotExist$ thrown if user does not exist in the DataStorage
\end{itemize}

\noindent get\_user\_texts(user : $String$)
\begin{itemize}
\item input: the user to get texts for
\item transition: None
\item output: list of texts for user
\item exception: $NoTexts$ thrown if the DataStorage does not currently have texts stored, $UserDoesNotExist$ thrown if user does not exist in the DataStorage
\end{itemize}

\noindent get\_user\_post\_labels(user : $String$)
\begin{itemize}
\item input: the user to get post labels for
\item transition: None
\item output: list of post labels for user
\item exception: $NoLabels$ thrown if the DataStorage does not currently have post labels stored, $UserDoesNotExist$ thrown if user does not exist in the DataStorage
\end{itemize}

\noindent get\_user\_post\_label\_counts(user : $String$, question : $String$)
\begin{itemize}
\item input: the user and question to get counts of post labels for
\item transition: None
\item output: a tuple of (number of negative scores in post history for user and question, number of positive scores, proportion of positive scores)
\item exception: $NoLabels$ thrown if the DataStorage does not currently have post labels stored, $UserDoesNotExist$ thrown if user does not exist in the DataStorage
\end{itemize}

\noindent get\_state()
\begin{itemize}
\item input: None
\item transition: None
\item output: a dictionary with entries: ``split" : number of the current split, and ``tr/te" : the string ``train" if currently focusing train ``test" otherwise
\item exception: None
\end{itemize}

\noindent set\_state(split : $Int$, train : $Bool$)
\begin{itemize}
\item input: split to set focus on and whether to focus train or test
\item transition: sets state variables split and train to input variables split and train, methods that reference a focused split will now act on the specified split
\item output: None
\item exception: $NotASplit$ thrown if input split refers to an invalid split
\end{itemize}

\subsubsection{Local Functions}

\noindent gen\_splits(num : $Int$, train\_prop : $Float$)
\begin{itemize}
\item input: number of train/test splits to create and what proportion of the data should be reserved for training in each split
\item transition: creates splits on TheData
\item output: None
\item exception: None
\end{itemize}


\subsection{Module ED Pipeline}

\subsection{Uses}

ED Parser, ED Cleaner, ED Output, ED Data Storage, ED Rep Model, ED Relabeler, ED Pred Model, ED Aggregator, ED Evaluator

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{4cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
run & None & None & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None

\subsubsection{Access Routine Semantics}

\noindent run():
\begin{itemize}
\item input: None
\item transition: runs the full pipeline
\item output: None
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Template Module ED Rep Model}

\subsection{Uses}

ED Data Storage

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{4cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
initialization & None & None & None \\
represent & $DataStorage$ & None & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

Rep Model : stores the rep model in running memory

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

DataStorage has text stored

\subsubsection{Access Routine Semantics}

\noindent initialize():
\begin{itemize}
\item input: None
\item transition: loads the rep model from disk
\item output: a RepModel() object
\item exception: None
\end{itemize}

\noindent represent(ds : $DataStorage$):
\begin{itemize}
\item input: a $DataStorage$ object
\item transition: stores a list of embeddings representing $ds$'s text for the current split
\item output: None
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Template Module ED Relabeler}

\subsection{Uses}

ED Rep Model, ED Data Storage

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{5cm} p{3cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
initialization & $DataStorage$ & $Relabeler$ & None \\
relabel\_all & $DataStorage$, Args & None & None \\
relabel\_question & $DataStorage$, $Int$, Args & None & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

DataStorage has embeddings and user labels stored

\subsubsection{Access Routine Semantics}

\noindent initialize(ds : $DataStorage$):
\begin{itemize}
\item input: a $DataStorage$ object
\item transition: initializes the relabeler to use the current split of $ds$ to relabel posts
\item output: a $Relabeler$ object
\item exception: None
\end{itemize}

\noindent relabel\_all(ds : $DataStorage$, HyperParameters : set of Args):
\begin{itemize}
\item input: a $DataStorage$ object and some number of hyper parameters used to calibrate the relabeling process (depends on implementation)
\item transition: calculates and stores a list of post labels in the current $ds$ split
\item output: None
\item exception: None
\end{itemize}

\noindent relabel\_question(ds : $DataStorage$, question : $Int$, HyperParameters : set of Args):
\begin{itemize}
\item input: a $DataStorage$ object, an int specify the questionnaire question to relabel, and some number of hyper parameters used to calibrate the relabeling process (depends on implementation)
\item transition: calculates and stores a list of post labels in the current $ds$ split for the specified question
\item output: None
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Template Module ED Pred Model}

\subsection{Uses}

ED Relabeler, ED Rep Model, ED Data Storage

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{5cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
initialize & $DataStorage$ & None & None \\
train & None & None & None \\
predict & $DataStorage$ & None & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

The DataStorage should have embeddings and post labels to train on

\subsubsection{Access Routine Semantics}

\noindent initialize(ds : $DataStorage$):
\begin{itemize}
\item input: a $DataStorage$ object
\item transition: initializes a $PredModel$ object to use the current ds split to train on
\item output: the initialized $PredModel$
\item exception: None
\end{itemize}

\noindent train():
\begin{itemize}
\item input: None
\item transition: trains the pred model on the ds split it was initialized on, saves the trained model to disk
\item output: None
\item exception: None
\end{itemize}

\noindent predict(ds : $DataStorage$):
\begin{itemize}
\item input: a $DataStorage$ object
\item transition: loads the previously trained pred model from disk, predicts scores for the currently focused ds split, and stores the predictions in ds
\item output: None
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Template Module ED Aggregator}

\subsection{Uses}

ED Relabeler, ED Pred Model, ED Data Storage

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{5cm} p{3cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
initialization & $DataStorage$, Args & $Aggregator$ & None \\
aggregate\_all & $DataStorage$, Args & None & None \\
aggregate\_question & $DataStorage$, $Int$, Args & None & None \\
score\_users & $DataStorage$, Args & None & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

DataStorage has embeddings and user labels stored

\subsubsection{Access Routine Semantics}

\noindent initialize(ds : $DataStorage$):
\begin{itemize}
\item input: a $DataStorage$ object
\item transition: initializes the aggregator to use the current split of $ds$ to aggregate posts
\item output: an $Aggregator$ object
\item exception: None
\end{itemize}

\noindent aggregate\_all(ds : $DataStorage$, HyperParameters : set of Args):
\begin{itemize}
\item input: a $DataStorage$ object and some number of hyper parameters used to calibrate the aggregating process (depends on implementation)
\item transition: initializes the aggregator to score users based on ds and HyperParameters
\item output: None
\item exception: None
\end{itemize}

\noindent aggregate\_question(ds : $DataStorage$, question : $Int$, HyperParameters : set of Args):
\begin{itemize}
\item input: a $DataStorage$ object, the question to initialize on, and some number of hyper parameters used to calibrate the aggregating process (depends on implementation)
\item transition: initializes the aggregator to score users based on ds and HyperParameters for the specified question
\item output: None
\item exception: None
\end{itemize}

\noindent score\_users(ds : $DataStorage$, HyperParameters : set of Args):
\begin{itemize}
\item input: a $DataStorage$ object and some number of hyper parameters used to calibrate the aggregating process (depends on implementation)
\item transition: calculates and stores user labels in the current $ds$ split based off of the $ds$'s post labels
\item output: None
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Module ED Trainer}

\subsection{Uses}

ED Parser, ED Cleaner, ED Output, ED Data Storage, ED Rep Model, ED Relabeler, ED Pred Model, ED Aggregator, ED Evaluator

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{5cm} p{3cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
train & None & None & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

DataStorage has embeddings and user labels stored

\subsubsection{Access Routine Semantics}

\noindent train():
\begin{itemize}
\item input: None
\item transition: finds the optimal hyperparameters for the different parts of the pipeline and writes them to a file
\item output: None
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Template Module ED Evaluator}

\subsection{Uses}

ED Aggregator, ED Metrics, ED Data Storage

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{5cm} p{3cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
initialization & $DataStorage$ & $Evaluator$ & None \\
evaluate & $DataStorage$ & None & None \\
get\_baselines & $DataStorage$ & $Tuple$ & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

DataStorage has embeddings and user labels stored

\subsubsection{Access Routine Semantics}

\noindent initialize(ds : $DataStorage$):
\begin{itemize}
\item input: a $DataStorage$ object
\item transition: initializes the evaluator to use the current split of $ds$ to calculate baselines posts
\item output: an $Evaluator$ object
\item exception: None
\end{itemize}

\noindent evaluate(ds : $DataStorage$):
\begin{itemize}
\item input: a $DataStorage$ object
\item transition: calculates accuracy metrics and prints a comparison between a set of baselines and the predictions stored in ds to the console
\item output: None
\item exception: None
\end{itemize}

\noindent get\_baselins(ds : $DataStorage$):
\begin{itemize}
\item input: a $DataStorage$ object
\item transition: calculates accuracy metrics for a set of baselines
\item output: a tuple where each entry is a list of metric scores for a baseline
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Module ED Metrics}

\subsection{Uses}

None

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{5cm} p{3cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
all\_metrics & $List$, $List$ & $List$ & None \\
MAE & $List$, $List$ & $Float$ & None \\
MZOE & $List$, $List$ & $Float$ & None \\
RS & $List$, $List$ & $Float$ & None \\
ECS & $List$, $List$ & $Float$ & None \\
SCS & $List$, $List$ & $Float$ & None \\
WCS & $List$, $List$ & $Float$ & None \\
GED & $List$, $List$ & $Float$ & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

DataStorage has embeddings and user labels stored

\subsubsection{Access Routine Semantics}

\noindent all\_metrics(preds : $List$, expects : $List$):
\begin{itemize}
\item input: predicted values and expected values
\item transition: None
\item output: returns all relevant error metrics evaluated for preds and expects
\item exception: None
\end{itemize}

\noindent MAE(preds : $List$, expects : $List$):
\begin{itemize}
\item input: predicted values and expected values
\item transition: None
\item output: returns MAE calculated for preds and expects
\item exception: None
\end{itemize}

\noindent MZOE(preds : $List$, expects : $List$):
\begin{itemize}
\item input: predicted values and expected values
\item transition: None
\item output: returns MAE calculated for preds and expects
\item exception: None
\end{itemize}

\noindent RS(preds : $List$, expects : $List$):
\begin{itemize}
\item input: predicted values and expected values
\item transition: None
\item output: returns MAE calculated for preds and expects
\item exception: None
\end{itemize}

\noindent ECS(preds : $List$, expects : $List$):
\begin{itemize}
\item input: predicted values and expected values
\item transition: None
\item output: returns MAE calculated for preds and expects
\item exception: None
\end{itemize}

\noindent SCS(preds : $List$, expects : $List$):
\begin{itemize}
\item input: predicted values and expected values
\item transition: None
\item output: returns MAE calculated for preds and expects
\item exception: None
\end{itemize}

\noindent WCS(preds : $List$, expects : $List$):
\begin{itemize}
\item input: predicted values and expected values
\item transition: None
\item output: returns MAE calculated for preds and expects
\item exception: None
\end{itemize}

\noindent GED(preds : $List$, expects : $List$):
\begin{itemize}
\item input: predicted values and expected values
\item transition: None
\item output: returns MAE calculated for preds and expects
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\newpage

\bibliographystyle {plainnat}
\bibliography {../../../refs/References}

\newpage    

\section{Appendix} \label{Appendix}
\subsection{Reflection}

\subsubsection{Limitations of the proposed solution.}
One of the primary limitations recognized in our design is that the performance of the various risk detectors are all turtlenecked with the spread of training data available to them. This primarily being enforced by biases present in the data which may skew results incorrectly, a prominent issue with all projects that rely on artificial intelligence to help predict an outcome. This bias can present itself as a decreased effectiveness for variations in cultural and linguistic backgrounds of the analyzed user data.

Additionally, this ties into the overall limitation of the system of how this tool is intended to be assistive and supplementary to trained mental health professionals, it is not meant to be the sole source of a diagnosis. Biases and limitations of the code structure will always offer an amount of machine error, which is why this program is to be used under the guidance of professionals who can help corroborate the results using their situation context and emotional intelligence, an ability that cannot ever truly be given to a computer.  

\subsubsection{Benefits and trade-offs of other potential solutions.}
Early in the design and planning process, the team experimented with the idea of using large language models similar to ChatGPT for diagnosis. This would allow us to leverage well documented and existing technologies in our efforts, providing a strong jumping off point for our workflow. Unfortunately, the team was able to soon discover research which showed that models like ChatGPT tend to draw undesirable parallels with their training data, resulting in the system unknowingly fabricating information in the input data which would provide incorrect results.

Something that was discovered while coding the project was that certain modules that could be represented as libraries benefited from being made abstract data types as the stored state of ADTs could be used to cache information in between calls to the module. This helped improve performance in various areas like when tuning a models parameters where a module needs to be run over and over.

\end{document}