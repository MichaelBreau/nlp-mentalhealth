\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,       % false: boxed links; true: colored links
linkcolor=red,          % color of internal links (change box color with linkbordercolor)
citecolor=blue,      % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan          % color of external links
}

\usepackage{array}

\externaldocument{../../SRS/SRS}

\input{../../Comments}
\input{../../Common}

\begin{document}

\title{Module Interface Specification for \progname{}}

\author{\authname}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
January 17, 2024 & 1.0 & Revision 0\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

See SRS Documentation at \url{https://github.com/MichaelBreau/nlp-mentalhealth/blob/main/docs/SRS/index.pdf}

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}

The following document details the Module Interface Specifications for
Natural Language Processing for Mental Health Risk Prediction 

Complementary documents include the System Requirement Specifications
and Module Guide.  The full documentation and implementation can be
found at \url{https://github.com/MichaelBreau/nlp-mentalhealth}.

\section{Notation}

The structure of the MIS for modules comes from \citet{HoffmanAndStrooper1995},
with the addition that template modules have been adapted from
\cite{GhezziEtAl2003}.  The mathematical notation comes from Chapter 3 of
\citet{HoffmanAndStrooper1995}.  For instance, the symbol := is used for a
multiple assignment statement and conditional rules follow the form $(c_1
\Rightarrow r_1 | c_2 \Rightarrow r_2 | ... | c_n \Rightarrow r_n )$.

The following table summarizes the primitive data types used by \progname. 

\begin{center}
\renewcommand{\arraystretch}{1.2}
\noindent 
\begin{tabular}{l l p{7.5cm}} 
\toprule 
\textbf{Data Type} & \textbf{Notation} & \textbf{Description}\\ 
\midrule
character & char & a single symbol or digit\\
list & $$[item, item,...]$$ & a list of objects of the same type\\
dict & $<key: T, val: T>$ & a dictionary of key value pairs\\
integer & $\mathbb{Z}$ & a number without a fractional component in (-$\infty$, $\infty$) \\
natural number & $\mathbb{N}$ & a number without a fractional component in [1, $\infty$) \\
real & $\mathbb{R}$ & any number in (-$\infty$, $\infty$)\\
\bottomrule
\end{tabular} 
\end{center}

\noindent
The specification of \progname \ uses some derived data types: sequences, strings, and
tuples. Sequences are lists filled with elements of the same data type. Strings
are sequences of characters. Tuples contain a list of values, potentially of
different types. In addition, \progname \ uses functions, which
are defined by the data types of their inputs and outputs. Local functions are
described by giving their type signature followed by their specification.

\section{Module Decomposition}

The following table is taken directly from the Module Guide document for this project.

\begin{table}[h!]
\centering
\begin{tabular}{p{0.2\textwidth} p{0.3\textwidth} p{0.4\textwidth}}
\toprule
\textbf{Level 1} & \textbf{Level 2} & \textbf{Level 3}\\
\midrule

{Hardware-Hiding} & None \\
\midrule

\multirow{3}{*}{Behaviour-Hiding} & \\ \cline{2-3}
& \multirow{2}{*}{Eating Disorder IO} & ED Input\\
& & ED Output\\
\midrule

\multirow{4}{*}{Software Decision} 
& \multirow{5}{*}{Depression Pipeline} & Depression Main\\ 
& & Depression Data Processing\\
& & Depression Feature Extraction\\
& & Depression Output\\ 
& & Depression Evaluation\\\cline{2-3}
& \multirow{4}{*}{Anorexia Pipeline} & Anorexia Main\\ 
& & Anorexia Parser\\
& & Anorexia Training\\
& & Anorexia Predictor\\ \cline{2-3}
& \multirow{5}{*}{Eating Disorder Pipeline} & ED Pipeline Manager\\
& & ED Tokenizer\\
& & ED Representation Model\\
& & ED Prediction Model\\
& & ED Transformation 1...n (represents multiple modules)\\
\bottomrule

\end{tabular}
\caption{Module Hierarchy}
\label{TblMH}
\end{table}

\newpage
~\newpage

\section{MIS for Search for Symptoms of Depression Module} \label{Module} 

\subsection{depression\_main}

Task 1 - Search for Symptoms of Depression for User Sentences - Main Module


\subsection{Uses}

Used for combining the various module functionalities in a pipeline format.\\ 
Uses depression\_process\_data, depression\_feature\_extraction, depression\_output, \\ 
depression\_accuracy\_evaluation

\subsection{Syntax}

\subsubsection{Exported Constants}

None 


\subsubsection{Exported Access Programs}

\begin{center}

\begin{tabular}{p{3cm}p{2cm}p{2cm}p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
N/A & N/A & N/A & - \\
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None


\subsubsection{Access Routine Semantics}

None


\subsubsection{Local Functions}

None

\subsection{depression\_process\_data}

Task 1 - Search for Symptoms of Depression for User Sentences - Data Processing Module

\subsection{Uses}

Used for parsing user posts and golden truth files

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
pathaddress & String & String & - \\
parsedata & String & Dictionary & - \\
processdata & String & Dictionary  & - \\
goldentruthsentences & String & Dictionary & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

\begin{itemize}
\item Data from user posts are in multiple trec file and the ground truth file is in a csv file and are present in the current task directory.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent pathaddress():
\begin{itemize}
\item transition: None
\item output: The path address for the data files
\item exception: None
\end{itemize}

\noindent parsedata():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to a list of strings containing user posts
\item exception: None
\end{itemize}

\noindent parsedata():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to a list of strings containing user posts, with gibberish information removed
\item exception: None
\end{itemize}

\noindent goldentruthsentences():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to an integer representing their depression symptom 
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\subsection{depression\_feature\_extraction}

Task 1 - Search for Symptoms of Depression for User Sentences - Feature Extraction Module

\subsection{Uses}

Used for predicting the top depression sentences that matches each symptom of depression

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
getFeatureWords & List & Dictionary & - \\
feature\_2\_vec & Dictionary, Dictionary & Dictionary & - \\
getEmbeddings & Dictionary, Dictionary,  & Dictionary & - \\
 & Dictionary &  &  \\
tf\_idf & Dictionary, Dictionary & Dictionary & - \\
 & Integer &  &  \\
vectorizePosts & Dictionary, Dictionary & Dictionary & - \\
 & Dictionary &  &  \\
cosine\_sim & Dictionary, List & Dictionary & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None

\subsubsection{Access Routine Semantics}

\noindent getFeatureWords():
\begin{itemize}
\item transition: None
\item output: A dictionary where each key represents a depression symptom, and the corresponding value is a list of strings representing feature words extracted from files.
\item exception: None
\end{itemize}

\noindent feature\_2\_vec():
\begin{itemize}
\item transition: None
\item output: Produces a dictionary where each key corresponds to a question number, and the associated value is a numpy array representing the vectorized features for that question. 
\item exception: None
\end{itemize}

\noindent getEmbeddings():
\begin{itemize}
\item transition: None
\item output: Outputs a dictionary containing word embeddings, filtered based on words present in the data, feature sets, and a given set of word embeddings
\item exception: None
\end{itemize}

\noindent tf\_idf():
\begin{itemize}
\item transition: None
\item output: Generates a dictionary where each key represents a document ID, and the associated value is a list of strings representing the top-k words based on TF-IDF scores.
\item exception: None
\end{itemize}

\noindent vectorizePosts():
\begin{itemize}
\item transition: None
\item output: A dictionary where each key represents a sentence, and the corresponding value is a numpy array representing the vectorized representation of the sentence.
\item exception: None
\end{itemize}

\noindent cosine\_sim():
\begin{itemize}
\item transition: None
\item output: A dictionary where each key represents a sentence, and the associated value is a float representing the cosine similarity between the sentence vector and a target vector.
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\subsection{depression\_output}

Task 1 - Search for Symptoms of Depression for User Sentences - Ouput Module

\subsection{Uses}

Used for generating output into a specific format

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
write\_to\_text\_file & Any, String & - & - \\
write\_dict\_to\_file & Dictionary, String & - & - \\
get\_questions & String & List & - \\
get\_top\_matchs & String, Dictionary & Dictionary & - \\

\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None

\subsubsection{Access Routine Semantics}

\noindent write\_to\_text\_file():
\begin{itemize}
\item transition: None
\item output: None
\item exception: None
\end{itemize}
\noindent write\_dict\_to\_file():
\begin{itemize}
\item transition: None
\item output: None
\item exception: None
\end{itemize}
\noindent get\_questions():
\begin{itemize}
\item transition: None
\item output: A list of strings representing symptom names extracted from a JSON questionnaire file.
\item exception: None
\end{itemize}
\noindent get\_top\_matchs():
\begin{itemize}
\item transition: None
\item output: A dictionary where each key represents a question index, and the associated value is a list of top matches based on user responses.
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\subsection{depression\_accuracy\_evaluation}

Task 1 - Search for Symptoms of Depression for User Sentences - Accuracy Evaluation Module


\subsection{Uses}

Used for determining the accuracy of generated results using various metrics

\subsection{Syntax}

\subsubsection{Exported Constants}

None 


\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{5.5cm} p{3cm} p{2.5cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
golden\_truth\_sentence\_data & String & Dictionary & - \\
get\_average\_precisions & Dictionary,  & List & - \\
 & Dictionary  &  &  \\
print\_accuracy & List, List, String & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None


\subsubsection{Access Routine Semantics}

\noindent golden\_truth\_sentence\_data():
\begin{itemize}
\item transition: None
\item output: A dictionary where each key represents a question index, and the associated value is a list of sentence IDs and their relevances based on a provided CSV file.
\item exception: None
\end{itemize}
\noindent get\_average\_precisions():
\begin{itemize}
\item transition: None
\item output: A list containing precision values and NDCG values calculated based on the provided sentence scores and golden truth values.
\item exception: None
\end{itemize}
\noindent print\_accuracy():
\begin{itemize}
\item transition: None
\item output: None
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\newpage

\section{MIS for Early Detection of Signs of Anorexia Module} \label{Module} 

\subsection{anorexia\_main}

Task 2 - Early Detection of Signs of Anorexia using User Posts - Main Module

\subsection{Uses}

Used for combining the various module functionalities in a pipeline format

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
N/A & N/A & N/A & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None

\subsubsection{Access Routine Semantics}

None

\subsubsection{Local Functions}

None

\subsection{anorexia\_parser}

Task 2 - Early Detection of Signs of Anorexia using User Posts - Parser Module

\subsection{Uses}

Used for parsing user posts and golden truth files

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
pathaddress & String & String & - \\
parsedata & String & Dictionary & - \\
goldentruth & String & Dictionary & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

\begin{itemize}
\item Data from user posts are in an xml file and the ground truth file is in a txt file and are present in the current working directory.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent pathaddress():
\begin{itemize}
\item transition: None
\item output: The path address for the data files
\item exception: None
\end{itemize}

\noindent parsedata():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to a list of strings containing user posts
\item exception: None
\end{itemize}

\noindent goldentruth():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to an integer representing their anorexia status (0 or 1)
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\subsection{anorexia\_training}

Task 2 - Early Detection of Signs of Anorexia using User Posts - Training Module

\subsection{Uses}

Used for training bertopic model on parsed data using golden truth values

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
bert & Dictionary & List, List & - \\
predictor & List, List & Dictionary & - \\
calculateaccuracy & Dictionary, Dictionary & None & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

\begin{itemize}
\item The model is trained on accurate data with correctly linked user-truth values.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent bert():
\begin{itemize}
\item transition: None
\item output: List 1: List of usernames, List 2: List of topics generated from the bertopic model with the indexes corresponding to the usernames from the first list
\item exception: None
\end{itemize}

\noindent predictor():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys and the predicted 0 or 1 integer linked
\item exception: None
\end{itemize}

\noindent calculateaccuracy():
\begin{itemize}
\item transition: None
\item output: Accuracy scores comparing golden truth to predictor values
\[ Precision (P) = \frac{|u \in U: d = g = 1|}{|u \in U: d = 1|} \]
\[ Recall (R) = \frac{|u \in U: d = g = 1|}{|u \in U: g = 1|} \]
\[ F-Score (F) = \frac{2*P*R}{P+R} \]
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\subsection{anorexia\_predictor}

Task 2 - Early Detection of Signs of Anorexia using User Posts - Predictor Module

\subsection{Uses}

Used for predicting new documents unseen by training

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
predict\_new & String & Integer & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None

\subsubsection{Access Routine Semantics}

\noindent predict\_new():
\begin{itemize}
\item transition: None
\item output: Integer 0 or 1 corresponding to the model prediction of anorexia negative or positive 
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\newpage

\section{MIS for Measuring the Severity of the Signs of Eating Disorders} \label{Module}

\subsection{Module ed\_input}

\subsection{Uses}

None

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{3cm} p{3cm} p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
read\_file & $String$ & $Dict$ & $IncorrectFileFormat$ \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

The input to read\_file will be a path to a file on the disk.

\subsubsection{Access Routine Semantics}

\noindent read\_file($pathaddress: String$):
\begin{itemize}
\item transition: None
\item output: $Dict\ of <username: String,\ posts: [post : String \vert post \in user's\ posts]>$
\item exception: If the input file is not correctly formatted
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Module ed\_output}

\subsection{Uses}

None

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{6cm} p{2cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
write\_file & $Str,\ $ & None & None \\
& $\ Dict<Str:List[Int]>$ &  &  \\
\hline

\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

The rest of the pipeline up to this point will produce a $Dict\ of\ <username: String,\ scores: [s_1, s_2, ..., s_{22}]>$ where $s_1, s_2, ..., s_{22}$ are the predicted scores for each of the eating disorder questionnaire's 22 questions

\subsubsection{Access Routine Semantics}

\noindent write\_file($file: Str,\ scores: Dict\ of\ <username: Str,\ scores: [s_1, s_2, ..., s_{22}]>$):
\begin{itemize}
\item transition: writes $scores$ to the file specified by $file$ where each line is of the format "username: s1, s2, ..., s22" for each user.
\item output: None
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Module ed\_pipeline}

\subsection{Uses}

ed\_input, ed\_tokenizer, ed\_rep\_model, ed\_pred\_model, ed\_output

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{4cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
run\_pipeline & $Str,\ Str$ & None & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

The first input to run\_pipeline is a path to a file on the disk

\subsubsection{Access Routine Semantics}

\noindent write\_file($in\_file: Str,\ out\_file: Str$):
\begin{itemize}
\item transition: calls ed\_input to read from $in\_file$, runs the full pipeline, and calls ed\_output to write user scores to $out\_file$.
\item output: None
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Module ed\_tokenizer}

\subsection{Uses}

None

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{4cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
tokenize & $Str,\ [Bool]$ & $List\ of\ Str$ & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None

\subsubsection{Access Routine Semantics}

\noindent write\_file($text: Str,\ options: [Bool]$):
\begin{itemize}
\item transition: None
\item output: A list of words representing $text$ split by whitespace after $text$ is processed in a number of ways specified by $options$.
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Module ed\_rep\_model}

\subsection{Uses}

None

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{4cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
represent & $[Str],\ [Bool]$ & $[Float]$ & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

The first input to represent will be the output of ed\_tokenizer: a processed list of the words in the input text split by whitespace.

\subsubsection{Access Routine Semantics}

\noindent represent($text: [Str],\ options: [Bool]$):
\begin{itemize}
\item transition: None
\item output: A list of floats representing $text$ encoded by some method into a numerical format, the details of the conversion are specified by $options$.
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Module ed\_pred\_model}

\subsection{Uses}

ed\_transform

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{5cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
predict & $<Str, [Float]>,\ [Bool]$ & $<Str, [Float]>$ & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

The first input to predict will be a dictionary of the outputs of ed\_rep\_model for each user.

\subsubsection{Access Routine Semantics}

\noindent represent($user\_data: <username: text, representation: [Float]>,\ options: List\ of\ Bool$):
\begin{itemize}
\item transition: None
\item output: A dictionary of $<username: String,\ scores: [s_1, s_2, ..., s_{22}]>$ where $s_1, s_2, ..., s_{22}$ are the predicted scores for each of the eating disorder questionnaire's 22 questions for each user $username$.
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None


\subsection{Module ed\_transform}

\subsection{Uses}

ed\_transform

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{5cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
predict & $<Str, [Float]>,\ [Bool]$ & $<Str, [Float]>$ & None \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

None

\subsubsection{Access Routine Semantics}

\noindent represent($user\_data: <username: text, representation: [Float]>,\ options: [Bool]$):
\begin{itemize}
\item transition: None
\item output: A dictionary of $<username: String,\ representation: [Float]>$ where each of the output's $representation$s is a transformation of the input $representation$s.
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\newpage

\bibliographystyle {plainnat}
\bibliography {../../../refs/References}

\newpage    

\section{Appendix} \label{Appendix}
\subsection{Reflection}

\subsubsection{Limitations of the proposed solution.}
One of the primary limitations recognized in our design is that the performance of the various risk detectors are all turtlenecked with the spread of training data available to them. This primarily being enforced by biases present in the data which may skew results incorrectly, a prominent issue with all projects that rely on artificial intelligence to help predict an outcome. This bias can present itself as a decreased effectiveness for variations in cultural and linguistic backgrounds of the analyzed user data.

Additionally, this ties into the overall limitation of the system of how this tool is intended to be assistive and supplementary to trained mental health professionals, it is not meant to be the sole source of a diagnosis. Biases and limitations of the code structure will always offer an amount of machine error, which is why this program is to be used under the guidance of professionals who can help corroborate the results using their situation context and emotional intelligence, an ability that cannot ever truly be given to a computer.  

\subsubsection{Benefits and trade-offs of other potential solutions.}
Early in the design and planning process, the team experimented with the idea of using large language models similar to ChatGPT for diagnosis. This would allow us to leverage well documented and existing technologies in our efforts, providing a strong jumping off point for our workflow. Unfortunately, the team was able to soon discover research which showed that models like ChatGPT tend to draw undesirable parallels with their training data, resulting in the system unknowingly fabricating information in the input data which would provide incorrect results.

\end{document}