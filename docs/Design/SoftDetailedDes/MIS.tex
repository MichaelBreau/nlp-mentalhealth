\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,       % false: boxed links; true: colored links
linkcolor=red,          % color of internal links (change box color with linkbordercolor)
citecolor=blue,      % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan          % color of external links
}

\usepackage{array}

\externaldocument{../../SRS/SRS}

\input{../Comments}
\input{../Common}

\begin{document}

\title{Module Interface Specification for \progname{}}

\author{\authname}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
1/17/2024 & 1.0 & Initial Rev 0\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

See SRS Documentation at \url{https://github.com/MichaelBreau/nlp-mentalhealth}

g - (Task 2) golden truth label \{0, 1\}

d - (Task 2) system prediction label \{0, 1\}

u - (Task 2) user u, member of set of Users (U)

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}

The following document details the Module Interface Specifications for
Natural Language Processing for Mental Health Risk Prediction 

Complementary documents include the System Requirement Specifications
and Module Guide.  The full documentation and implementation can be
found at \url{https://github.com/MichaelBreau/nlp-mentalhealth}.

\section{Notation}

The structure of the MIS for modules comes from \citet{HoffmanAndStrooper1995},
with the addition that template modules have been adapted from
\cite{GhezziEtAl2003}.  The mathematical notation comes from Chapter 3 of
\citet{HoffmanAndStrooper1995}.  For instance, the symbol := is used for a
multiple assignment statement and conditional rules follow the form $(c_1
\Rightarrow r_1 | c_2 \Rightarrow r_2 | ... | c_n \Rightarrow r_n )$.

The following table summarizes the primitive data types used by \progname. 

\begin{center}
\renewcommand{\arraystretch}{1.2}
\noindent 
\begin{tabular}{l l p{7.5cm}} 
\toprule 
\textbf{Data Type} & \textbf{Notation} & \textbf{Description}\\ 
\midrule
character & char & a single symbol or digit\\
integer & $\mathbb{Z}$ & a number without a fractional component in (-$\infty$, $\infty$) \\
natural number & $\mathbb{N}$ & a number without a fractional component in [1, $\infty$) \\
real & $\mathbb{R}$ & any number in (-$\infty$, $\infty$)\\
symbol & $\in$ & member of symbol\\
\bottomrule
\end{tabular} 
\end{center}

\noindent
The specification of \progname \ uses some derived data types: sequences, strings, and
tuples. Sequences are lists filled with elements of the same data type. Strings
are sequences of characters. Tuples contain a list of values, potentially of
different types. In addition, \progname \ uses functions, which
are defined by the data types of their inputs and outputs. Local functions are
described by giving their type signature followed by their specification.

\section{Module Decomposition}

The following table is taken directly from the Module Guide document for this project.

\begin{table}[h!]
\centering
\begin{tabular}{p{0.3\textwidth} p{0.6\textwidth}}
\toprule
\textbf{Level 1} & \textbf{Level 2}\\
\midrule

{Hardware-Hiding} & ~ \\
\midrule

\multirow{7}{0.3\textwidth}{Behaviour-Hiding} & Input Parameters\\
& Output Format\\
& Output Verification\\
& Temperature ODEs\\
& Energy Equations\\ 
& Control Module\\
& Specification Parameters Module\\
\midrule

\multirow{3}{0.3\textwidth}{Software Decision} & {Sequence Data Structure}\\
& ODE Solver\\
& Plotting\\
\bottomrule

\end{tabular}
\caption{Module Hierarchy}
\label{TblMH}
\end{table}

\newpage
~\newpage

\section{MIS for Search for Symptoms of Depression Module} \label{Module} 

\subsection{Module}

Task 1 - Search for Symptoms of Depression for User Sentences 


\subsection{Uses}

Used to rank each input sentence by its correlation to a given depression symptom and returns the 1000 sentences with the highest correlation to said depression symptom. Each sentence will receive a level of correlation for each of the 21 given depression symptoms (totaling an output of 21,000 sentences). These results for user sentences will be tested against the results each user gave when filling out the BDI Questionnaire regarding there depression symptoms.

\subsection{Syntax}

\subsubsection{Exported Constants}

None 


\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
path\_address & String & String & - \\
parse\_data & String & Dictionary & - \\
filter\_sentences & Dictionary & Dictionary & - \\
write\_top\_sentences & List, String & - & - \\ 
detect\_depression\_symptom & String, String & Integer & - \\ 
normalize\_symptom\_scores & Dictionary & List & - \\ 

\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

\begin{itemize}
\item Data for each users sentences are in there own .trec file and the jsonl file acts as a master list of sentences containing all sentences across all users in one jsonl file.
\item The users answered the BDI questionnaire honestly so we can take that data as being accurate when we use it. 
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent path\_address():
\begin{itemize}
\item transition: None
\item output: A string representing the address's of all trec files
\item exception:  
\end{itemize}

\noindent parse\_data():
\begin{itemize}
\item transition: None
\item output: A dictionary containing every sentence where the key is the sentence id and the value is the sentence itself.
\item exception: None
\end{itemize}

\noindent filter\_sentences():
\begin{itemize}
\item transition: None
\item output: A dictionary containing all sentences that were not filtered out by the filter function due to being deemed as low quality or irrelevant sentences for testing. The key for each dictionary entry is the sentence id and the value is the sentence itself.
\item exception: None 
\end{itemize}

\noindent write\_top\_sentences():
\begin{itemize}
\item transition: None
\item output: None
\item exception: None
\end{itemize}

\noindent detect\_depression\_symptom():
\begin{itemize}
\item transition: None
\item output: A integer that represents the correlation of the inputted sentence to the inputted symptom.
\item exception: 
\end{itemize}

\noindent normalize\_symptom\_scores():
\begin{itemize}
\item transition: None
\item output: A list of lists where each inner array represents a sentence. The first element in the inner list is the sentence id and the second is the score for the given depression symptom from 1-10. The outputted list of lists will be sorted by there depression symptom score from highest to lowest.
\item exception: 
\end{itemize}


\subsubsection{Local Functions}

None

\newpage

\section{MIS for Early Detection of Signs of Anorexia Module} \label{Module} 

\subsection{Module}

Task 2 - Early Detection of Signs of Anorexia using User Posts

\subsection{Uses}

Used for predicting early signs of anorexia using aggregates of user posts trained on data from users who were to known to not have or have anorexia symptoms.

\subsection{Syntax}

\subsubsection{Exported Constants}

None

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4.5cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
pathaddress & String & String & - \\
parsedata & String & Dictionary & - \\
goldentruth & String & Dictionary & - \\
bert & Dictionary & List, List & - \\
predictor & List, List & Dictionary & - \\
calculateaccuracy & Dictionary, Dictionary & None & - \\
gettopicdistribution & List, List & None & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

None

\subsubsection{Environment Variables}

None

\subsubsection{Assumptions}

\begin{itemize}
\item Data from user posts are in an xml file and the ground truth file is in a txt file and are present in the current working directory.
\item The model is trained on accurate data with correctly linked user-truth values.
\end{itemize}

\subsubsection{Access Routine Semantics}

\noindent pathaddress():
\begin{itemize}
\item transition: None
\item output: The path address for the data files
\item exception: None
\end{itemize}

\noindent parsedata():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to a list of strings containing user posts
\item exception: None
\end{itemize}

\noindent goldentruth():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys connected to an integer representing their anorexia status (0 or 1)
\item exception: None
\end{itemize}

\noindent bert():
\begin{itemize}
\item transition: None
\item output: List 1: List of usernames, List 2: List of topics generated from the bertopic model with the indexes corresponding to the usernames from the first list
\item exception: None
\end{itemize}

\noindent predictor():
\begin{itemize}
\item transition: None
\item output: Dictionary with usernames as keys and the predicted 0 or 1 integer linked
\item exception: None
\end{itemize}

\noindent calculateaccuracy():
\begin{itemize}
\item transition: None
\item output: Accuracy scores comparing golden truth to predictor values
\[ Precision (P) = \frac{|u \in U: d = g = 1|}{|u \in U: d = 1|} \]
\[ Recall (R) = \frac{|u \in U: d = g = 1|}{|u \in U: g = 1|} \]
\[ F-Score (F) = \frac{2*P*R}{P+R} \]
\item exception: None
\end{itemize}

\noindent gettopicdistribution():
\begin{itemize}
\item transition: None
\item output: List with index representing the topic distribution of users with sepperation into golden truth of 0 and 1s
\item exception: None
\end{itemize}

\subsubsection{Local Functions}

None

\newpage

\section{MIS for Measuring the Severity of the Signs of Eating Disorders} \label{Module} \wss{Use labels for
  cross-referencing}

\wss{You can reference SRS labels, such as R\ref{R_Inputs}.}

\wss{It is also possible to use \LaTeX for hypperlinks to external documents.}

\subsection{Module}

\wss{Short name for the module}

\subsection{Uses}


\subsection{Syntax}

\subsubsection{Exported Constants}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{4cm} p{4cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\wss{accessProg} & - & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

\wss{Not all modules will have state variables.  State variables give the module
  a memory.}

\subsubsection{Environment Variables}

\wss{This section is not necessary for all modules.  Its purpose is to capture
  when the module has external interaction with the environment, such as for a
  device driver, screen interface, keyboard, file, etc.}

\subsubsection{Assumptions}

\wss{Try to minimize assumptions and anticipate programmer errors via
  exceptions, but for practical purposes assumptions are sometimes appropriate.}

\subsubsection{Access Routine Semantics}

\noindent \wss{accessProg}():
\begin{itemize}
\item transition: \wss{if appropriate} 
\item output: \wss{if appropriate} 
\item exception: \wss{if appropriate} 
\end{itemize}

\wss{A module without environment variables or state variables is unlikely to
  have a state transition.  In this case a state transition can only occur if
  the module is changing the state of another module.}

\wss{Modules rarely have both a transition and an output.  In most cases you
  will have one or the other.}

\subsubsection{Local Functions}

\wss{As appropriate} \wss{These functions are for the purpose of specification.
  They are not necessarily something that is going to be implemented
  explicitly.  Even if they are implemented, they are not exported; they only
  have local scope.}

\newpage

\bibliographystyle {plainnat}
\bibliography {../../../refs/References}

\newpage

\section{Appendix} \label{Appendix}

\subsection{Reflection} 

\subsubsection{Limitations of the proposed solution.}
One of the primary limitations recognized in our design is that the performance of the various risk detectors are all turtlenecked with the spread of training data available to them. This primarily being enforced by biases present in the data which may skew results incorrectly, a prominent issue with all projects that rely on artificial intelligence to help predict an outcome. This bias can present itself as a decreased effectiveness for variations in cultural and linguistic backgrounds of the analyzed user data.

Additionally, this ties into the overall limitation of the system of how this tool is intended to be assistive and supplementary to trained mental health professionals, it is not meant to be the sole source of a diagnosis. Biases and limitations of the code structure will always offer an amount of machine error, which is why this program is to be used under the guidance of professionals who can help corroborate the results using their situation context and emotional intelligence, an ability that cannot ever truly be given to a computer.  

\subsubsection{Benefits and trade-offs of other potential solutions.}
Early in the design and planning process, the team experimented with the idea of using large language models similar to ChatGPT for diagnosis. This would allow us to leverage well documented and existing technologies in our efforts, providing a strong jumping off point for our workflow. Unfortunately, the team was able to soon discover research which showed that models like ChatGPT tend to draw undesirable parallels with their training data, resulting in the system unknowingly fabricating information in the input data which would provide incorrect results.


\end{document}