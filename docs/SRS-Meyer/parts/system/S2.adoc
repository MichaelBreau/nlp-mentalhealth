[#s2,reftext=S.2]
=== (S.2) Functionality
:stem: latexmath

ifdef::env-draft[]
TIP: _**This is the bulk of the System book, describing elements of functionality (behaviors)**. This chapter corresponds to the traditional view of requirements as defining "**what the system does**”. It is organized as one section, S.2.n, for each of the components identified in <<s1>>, describing the corresponding behaviors (functional and non-functional properties)._  <<BM22>>
endif::[]

This section describes in further detail the components listed in the previous section by describing their functional and non-functional requirements.

**General and Security**

Non-Functional Requirements:

- GR1: The system should be compatible on MacOS, Windows, and Linux.
- GR2: Copyrighted content should not be included in the output without reference.
- SR1: The system will be tested periodically to detect a potential lack of processing power.
- SR2: Sensitive user data must not be present within the results generated.

Each task will have their own accuracy metrics that the quality of the models predictions will be evaluated on.

==== Task 1: Search for Symptoms of Depression Component

Functional Requirements:

- T1FR-1: The system will be able to parse both xml and jsonl files.
- T1FR-2: The system will rank input sentences from users based on their correlation to 21 depression symptoms from the beck depression index.
- T1FR-3: The system will send the predictions to a txt file in the format "{symptom_number}, Q0, {sentence-id}, {position_in_ranking}, {score}, {system_name}".

==== Task 2: Early Detection of Signs of Anorexia Component

Functional Requirements:

- T2FR-1: The system will be able to parse both xml and jsonl files.
- T2FR-2: The system will make predictions given a set of a user's posts.
- T2FR-3: The system will allow posts to be added to a user's set of posts and the system will update the prediction for that user.
- T2FR-4: The system will send the predictions to a txt file in the format "{username} {prediction (0 or 1)}" with each entry being on a separate line.


==== Task 3: Measuring the Severity of the Signs of Eating Disorders Component

**General Functional Requirements:**

- T3FR-1: The system will be able to parse jsonl files of an individual's post history.
- T3FR-2: The system will make predictions given a set of a user's posts.
- T3FR-3: The system will send the predictions to a txt file in the format "{username} {prediction (0-6) for Q1} ... {prediction (0-6) for Q28}" with each individual being on a separate line.

**Accuracy Functional Requirements:**

These functional requirements cover how the accuracy of the model will be evaluated. These requirements involve evaluating the system's performance against a set of three baselines: guess zero for every question, guess six for every question, and guess the average for every question. If the system fails to outperform these baselines it does not represent an improvement over guessing and will be considered a failure.

Performance will be evaluated on a number of metrics, the following is taken from <<EROV>> and discusses the metrics that will be used to evaluate accuracy for task 3:

Evaluation is based on the following effectiveness metrics:

- Mean Zero-One Error (_MZOE_) between the questionnaire filled by the real user and
the questionnaire filled by the system (i.e. fraction of incorrect predictions).
+
image::equations/MZOE.png[scale=50%,align="center"]
+
where _f_ denotes the classification done by an automatic system, _Q_ is the set of questions
of each questionnaire, _q~i~_ is the i-th question, _R(q~i~)_ is the real user’s answer for the i-th
question and _f(q~i~)_ is the predicted answer of the system for the i-th question. Each user
produces a single _MZOE_ score and the reported _MZOE_ is the average over all _MZOE_
values (mean _MZOE_ over all users).

- Mean Absolute Error (_MAE_) between the questionnaire filled by the real user and the
questionnaire filled by the system (i.e. average deviation of the predicted response from
the true response).
+
image::equations/MAE.png[scale=50%,align="center"]
+
Again, each user produces a single _MAE_ score and the reported _MAE_ is the average
over all _MAE_ values (mean _MAE_ over all users).

The following measures are based on aggregated scores obtained from the EDE-Q questionnaires.

- Restraint Subscale (RS): Given a questionnaire, its restraint score is obtained as the
mean response to the first five questions. This measure computes the RMSE between the
restraint ED score obtained from the questionnaire filled by the real user and the restraint
ED score obtained from the questionnaire filled by the system.
Each user _u~i~_ is associated with a real subscale ED score (referred to as _R~RS~(u~i~)_) and an
estimated subscale ED score (referred to as _f~RS~(u~i~)_). This metric computes the RMSE
between the real and an estimated subscale ED scores as follows:
+
image::equations/RS.png[scale=50%,align="center"]
+
where _U_ is the user set.

- Eating Concern Subscale (ECS): Given a questionnaire, its eating concern score is
obtained as the mean response to the following questions (7, 9, 19, 21, 20). This metric
computes the RMSE between the eating concern ED score obtained from
the questionnaire filled by the real user and the eating concern ED score obtained from
the questionnaire filled by the system.
+
image::equations/ECS.png[scale=50%,align="center"]

- Shape Concern Subscale (SCS): Given a questionnaire, its shape concern score is
obtained as the mean response to the following questions (6, 8, 23, 10, 26, 27, 28, 11). This
metric computes the RMSE between the shape concern ED score obtained
from the questionnaire filled by the real user and the shape concern ED score obtained
from the questionnaire filled by the system.
+
image::equations/SCS.png[scale=50%,align="center"]

- Weight Concern Subscale (WCS): Given a questionnaire, its weight concern score is
obtained as the mean response to the following questions (22, 24, 8, 25, 12). This metric
computes the RMSE between the weight concern ED score obtained from
the questionnaire filled by the real user and the weight concern ED score obtained from
the questionnaire filled by the system.
+
image::equations/WCS.png[scale=50%,align="center"]

- Global ED (GED): To obtain an overall or ‘global’ score, the four subscales scores are
summed and the resulting total divided by the number of subscales (i.e. four). This
metric computes the RMSE between the real and an estimated global ED scores as follows:
+
image::equations/GED.png[scale=50%,align="center"]

MAE is the most important metric out of all of these as it gives the clearest picture of how well the system is performing overall. MZOE is less valuable as it only shows how many answers the system got exactly right, having a good MZOE but a bad MAE isn't a good result as getting a solid amount of answers exactly right but all the others very wrong is not desirable behaviour. The measures based on aggregated scores are useful for seeing what parts of the questionnaire the system is good at predicting for, but again, if any of these metrics are good while MAE is poor this does not represent desirable behaviour. The system should outperform the three baselines on MAE or at least tie them on MAE and outperform on another metric.

This leads to a set of three accuracy requirements:

- T3FR-4: The model will outperform guessing all zeros on MAE OR tie MAE and outperform on at least one of the other metrics.
- T3FR-5: The model will outperform guessing all sixes on MAE OR tie MAE and outperform on at least one of the other metrics.
- T3FR-6: The model will outperform guessing the average on MAE OR tie MAE and outperform on at least one of the other metrics.

