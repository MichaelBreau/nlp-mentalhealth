[#s6,reftext=S.6]
=== (S.6) Verification and acceptance criteria

ifdef::env-draft[]
TIP: _Specification of the conditions under which an implementation will be deemed satisfactory. Here, "verification" as shorthand for what is more explicitly called "Verification & Validation" (V&V), covering several levels of testing — module testing, integration testing, system testing, user acceptance testing — as well as other techniques such as static analysis and, when applicable, program proving._  <<BM22>>
endif::[]

- The system should meet the accuracy requirements for each component laid out in S.2. This will be determined by taking the labelled data from eRisk, splitting it into a train set and a test set, training the prediction models on the train set, and then predicting answers for the test set. These predictions will be evaluated against the known values of the test set on the accuracy measures laid out in S.2 and if they outperform the baselines described in S.2 the implementation will be deemed satisfactory.

- The system should perform in the top 50% of systems submitted to eRisk this year for each of the tasks. Given these results will be released by eRisk sometime after the capstone course wraps up the result of this criteria will not be included in the final capstone documentation.

- The predictions models used in the system should be generalizable beyond the eRisk data we are developing on. This is a difficult and vague thing to prove, that the system's models don't just perform well on the data they are developed on but that they will perform well on any instance of the problem the model is built to solve. For the purposes of the project this criteria will be considered met if a reasonable justification of generalizablity is made for each model, including an analysis of any factors that negatively impact generalizability.

